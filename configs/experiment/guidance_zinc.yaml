# @package _global_
general:
    name : 'guidance_homo'
    gpus : 1
    wandb: 'disabled'
    sample_every_val: 1
    samples_to_generate: 10
    final_model_samples_to_generate: 10
    final_model_chains_to_save: 0
    samples_to_save: 2
    chains_to_save: 0
    number_chain_steps: 10        # Number of frames in each gif
    # THIS SHOULD BE THE SAME AS THE REGRESSION MODEL THAT IS LOADED
    guidance_target: 'homo'            # 'mu', 'homo', 'both', 'no-target'
    trained_regressor_path: "/root/DiGress/src/outputs/2024-03-25/02-27-14/checkpoints/graph-tf-model/parp1val/epoch_mae=0.0515_epoch=4.ckpt"
    test_only: True
train:
    batch_size: 1               # Needs to be 1 for testing
    save_model: False
model:
    n_layers: 12
    lambda_train: [5, 0]
    type: 'discrete'
    transition: 'marginal'                          # uniform or marginal
    model: 'graph_tf'
    diffusion_steps: 500
    diffusion_noise_schedule: 'cosine'              # 'cosine', 'polynomial_2'
    extra_features: 'all'                              # 'all', 'cycles', 'eigenvalues' or null

  # Do not set hidden_mlp_E, dim_ffE too high, computing large tensors on the edges is costly
  # At the moment (03/08), y contains quite little information
    hidden_mlp_dims: { 'X': 256, 'E': 128, 'y': 256}

  # The dimensions should satisfy dx % n_head == 0
    hidden_dims: { 'dx': 256, 'de': 64, 'dy': 128, 'n_head': 8, 'dim_ffX': 256, 'dim_ffE': 128, 'dim_ffy': 256}
guidance:
    lambda_guidance: 300.0
    n_experiments: 2          # Change to 100
dataset:
    remove_h: True